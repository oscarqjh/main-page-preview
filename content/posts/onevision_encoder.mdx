---
title: "OneVision Encoder: Codec-Aligned Sparsity as a Foundational Principle for Multimodal Intelligence"
description: "Our hypothesis: AGI is a compression problem. We introduce Codec Patchification that processes only 3.1%-25% of regions, achieving 4.1% improvement on video tasks while outperforming Qwen3-ViT and SigLIP2."
publishDate: "2026-01-15"
mainTags: ["models"]
tags:
  [
    "models",
    "multimodal"
  ]
thumbnail: "/images/blog_thumbnails/onevision_encoder.png"
authors:
  - name: "LMMs Lab"
    main: true
  - name: "Glint Lab"
  - name: "AIM for Health Lab"
  - name: "MVP Lab"
bibtex: |
  @article{onevision_encoder_2026,
    title={OneVision Encoder},
    author={LMMs Lab, Glint Lab, AIM for Health Lab, MVP Lab},
    journal={arXiv preprint},
    year={2026}
  }
---

## Core Hypothesis

**AGI is a compression problem.** Neural architecture should align with the statistical structure of visual data - not fight against it.

## Method: Codec Patchification

We introduce **Codec Patchification** - a paradigm where architecture mirrors how information is actually structured in visual streams:

- **Ultra-sparse processing**: Only 3.1%-25% of spatial regions are processed, guided by codec-style saliency
- **3D RoPE**: Positional encoding that captures spatiotemporal structure across frames
- **Cluster discrimination**: Contrastive learning with hierarchical concept banks for semantic grounding

Instead of treating all pixels equally, we process visual data the way video codecs do: identify what matters, discard redundancy, preserve signal.

## Results

OneVision Encoder achieves:
- **4.1% improvement** on video understanding tasks (MVBench, VideoMME, Perception Test)
- **Outperforms Qwen3-ViT and SigLIP2** on both video and image benchmarks
- State-of-the-art on document understanding (DocVQA, ChartQA, OCRBench)

<img src="/onevision-encoder/images/method.png" alt="OneVision Encoder Method Overview" style={{width: "100%", maxWidth: "600px", margin: "2rem auto", display: "block"}} />

For more details, interactive demos, and full benchmark results, see the [full project page](/onevision-encoder/index.html).
