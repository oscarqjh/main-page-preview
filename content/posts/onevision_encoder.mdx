---
title: "OneVision Encoder: the First HEVC-Style Vision Transformer with Advanced Multimodal Capabilities"
description: "A vision transformer that resolves the frame-computation trade-off using HEVC video compression principles, achieving state-of-the-art results on video and image benchmarks."
publishDate: "2026-01-15"
mainTags: ["models"]
tags:
  [
    "models",
    "multimodal"
  ]
thumbnail: "/images/blog_thumbnails/onevision_encoder.png"
authors:
  - name: "LMMs Lab"
    main: true
  - name: "Glint Lab"
  - name: "AIM for Health Lab"
  - name: "MVP Lab"
bibtex: |
  @article{onevision_encoder_2026,
    title={OneVision Encoder},
    author={LMMs Lab, Glint Lab, AIM for Health Lab, MVP Lab},
    journal={arXiv preprint},
    year={2026}
  }
---

## Introduction

Video understanding models face a fundamental trade-off: processing more frames captures richer temporal information but increases computation quadratically. Traditional approaches address this through sparse frame sampling, but this discards fine-grained motion dynamics and treats all spatial regions equally — wasting computation on static backgrounds.

We present **OneVision Encoder**, a vision transformer that resolves this trade-off using principles from HEVC video compression. Instead of sampling sparse frames densely (all patches from few frames), we sample dense frames sparsely (important patches from many frames). Our codec-style patch selection identifies temporally-salient regions — areas with motion, object interactions, or semantic changes — and processes only these informative patches.

Combined with global contrastive learning using a 2M concept bank, OneVision Encoder achieves state-of-the-art results on video benchmarks (MVBench, VideoMME, Perception Test) and image understanding tasks (DocVQA, ChartQA, OCRBench).

<img src="/onevision-encoder/images/method.png" alt="OneVision Encoder Method Overview" style={{width: "100%", maxWidth: "600px", margin: "2rem auto", display: "block"}} />

For more details, interactive demos, and full benchmark results, see the [full project page](/onevision-encoder/index.html).
